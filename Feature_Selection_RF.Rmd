---
title: "Feature_Select_RF"
author: "ClareCallahan"
date: "4/17/2021"
output: html_document
---

```{r setup, include=FALSE}
loadlibs = function(libs) {
  for(lib in libs) {
    class(lib)
    if(!do.call(require,as.list(lib))) {install.packages(lib)}
    do.call(require,as.list(lib))
  }
}
libs = c("tidyverse","data.table","stargazer", "knitr", "shiny",
         "tidymodels", "lubridate", "rpart.plot", "caret", "e1071",
         "readxl", "fuzzyjoin", "mgcv", "randomForest", "glmnet")
loadlibs(libs)
```

```{r}
setwd("~/GitHub/Covid-19-Closure-Impact/Data")

#df<-read.csv('Covid_Pred.csv')

df<- read.csv('shiny_merged_dataset_example.csv')%>% 
  mutate_at(c('week_first_date'), ~ as.Date(., "%Y-%m-%d")) %>% 
  mutate(two_week_forecast_date = week_first_date + 14) %>% 
  mutate_if(is.character, as.factor) %>% 
  select(-1)
# Get latest date 
latest_date = max(original_df$week_first_date)
#Two week outcome 
twoWeek_df = original_df %>% 
  select(week_first_date, State, Outcome.Variable) %>% 
  rename(two_week_outcome = Outcome.Variable,
         two_week_forecast_date = week_first_date) 
#Merge with original to create a working df
working_df = original_df %>% 
  left_join(twoWeek_df,
            by = c("State" = "State",
                   "two_week_forecast_date" = "two_week_forecast_date")) %>% 
  mutate(year = as.factor(year(two_week_forecast_date)),
         week = as.factor(week(two_week_forecast_date)))


#names(df)[names(df) == "Outcome.Variable"] <- "original_y" #creating consitency 
#names(df)[names(df) == "Other"] <- "Other_Race"  #"Other is not meaningful in output

```



```{r}


drops<-c( "year", "week","week_first_date", "two_week_forecast_date") #droping 
df <-df[, -which(names(df) %in% drops)]
##Moving Ouctome Variable to front of dataset for ease of splitting
col_idx <- grep("^y$", names(df))
df <- df[, c(col_idx, (1:ncol(df))[-col_idx])]



```
##Split
```{r}

end<-ncol(df)
x <- df[,2:end]
y <- df[,1]

#Removing Y from the tuning paratmers 

```

## Tuning
The following is tuning the number of varaibles reandomple sampled as candiate at each split (mtry)
```{r}

# Algorithm Tune (tuneRF)
set.seed(10)
bestmtry <- tuneRF(x, y, stepFactor=1.5, improve=1e-5, ntree=500)
print(bestmtry)

bestmtry_var<- bestmtry[1,1].0

```


```{r}

rf <- randomForest(y ~ ., mtry= bestmtry_var, 
  data=df
)

varImpPlot(rf,sort=TRUE, n.var=min(10, nrow(rf$importance)),
           type=NULL, class=NULL, scale=TRUE, 
           main=deparse(substitute(rf))) 

### GAMS
features <- as.data.frame(rf$importance)
features <-as.data.frame(setNames(cbind(rownames(features), features, row.names= NULL), c("Feature", "NodPurity"))) 

top<- top_n(features, 10, features$NodPurity)
#toplist<- as.list(top$Feature) #list variable did not work in gam

#one<- as.character(top[1,1])
top_f<-as.vector(top$Feature)

new<-df%>%
select(one_of(c(top_f)))

new$y<-df$y



#glment select levels of sparcity....  

```


###Geocoding 


#Data from: https://public.opendatasoft.com/explore/dataset/us-zip-code-latitude-and-longitude/export/ 
Process needed to create 2D for 'state' to be incorporated into GLM with poly option 



```{r}

#setwd("~/GitHub/Covid-19-Closure-Impact/Data")

geo<- read.csv('us-zip-code-latitude-and-longitude.csv', header= FALSE, stringsAsFactors = FALSE)

geo<- as.data.frame(geo)

geo<-geo%>% separate(V1, into=c("Zip", "City", "State", "Latitude","Longitude","Timezone","Daylight_savings", "geopoint"), sep=";" )

geo<- geo[-1,]

geo$Latitude<-as.numeric(geo$Latitude)
geo$Longitude<-as.numeric(geo$Longitude)

state_latLong <- geo%>%
  group_by(State)%>%
  summarise(Latitude = mean(Latitude, na.rm = TRUE),
            Longitude = mean(Longitude, na.rm = TRUE))

```

#Joining Long/Lat data and selected features
```{r}
# this step should be moved to data cleaning, ask if their data is by state or county, county can be a direct match to the original dataset 
features<- left_join(new, state_latLong, by='State')
id<-rownames(features)
features<-cbind(id=id, features)

```

```{r}
features1<-features[, -which(names(features) %in% c("State"))]

##need to undo this at the end

col_idx <- grep("^y$", names(features1))
features1 <- features1[, c(col_idx, (1:ncol(features1))[-col_idx])]
head(features1)

 feat_v2 <- function(df, column_numbers) {

  df %>% 
    mutate_at(vars(column_numbers), funs(sqr = (.)^2))%>%
   mutate_at(vars(column_numbers), funs(cube =(.)^3))
}

 
glm_feats<-feat_v2(features1, 3:13) #do not include y or "id" in poly calcs

one<- as.character(top[1,1])

typeof(features1$two_week_prior)

```


###CV Glmnet 


```{r}
##Train/Test split 
n<-glm_feats%>% count() 
n<-as.numeric(n/2)
data2= features1[sample(1:nrow(glm_feats)),]  # permute rows

datatrain = data2[(1:n),]
datatest = data2[-(1:n),]

```


##Glmnet 
```{r}

train_glm<- cv.glmnet(
  x = datatrain %>% select(-y, -id) %>% as.matrix(),
  y = datatrain$y, relax= FALSE)

i <- which(train_glm$lambda == train_glm$lambda.min)
mse.min <- train_glm$cvm[i]


glm_preds <-predict(train_glm, newx = datatest %>% select(-y, -id)%>% as.matrix(), newy= datatest$y)

combo<- as.data.frame(cbind(glm_preds, datatest$y))
combo<-combo%>%
  rename(Preds='1', 
         Original = V2)

```

```{r}

plot(glm_preds)
plot(glm_preds,xvar="lambda",label=TRUE)

```
```{r}

plot(combo)

combo$Error_abs <-100*abs(combo$Original - combo$Preds)/combo$Original

combo$MSE<-(combo$Original - combo$Preds)^2 

mean(combo$MSE)
mean(combo$Error_abs)

ggplot(combo, aes(x=Error_abs)) + geom_boxplot()
ggplot(combo, aes(x=MSE)) + geom_boxplot()

```


#df1 = df %>%
# mutate_if(is.character, as.factor) #%>% 
#mutate_if(is.factor, forcats::fct_lump_min, min=100) 
#df1$new_cases<- as.factor(df1$new_cases)

t<- as.numeric(count(df)*.75)

set.seed(12345) 
df2 = df[sample(1:nrow(df)),]
train = df2[1:t,]
test = df2[-(1:t),]


control <- trainControl(method="repeatedcv", number=10, repeats=3, search="grid")
set.seed(seed)
tunegrid <- expand.grid(.mtry=c(1:15))
rf_gridsearch <- train(Class~., data=dataset, method="rf", metric=metric, tuneGrid=tunegrid, trControl=control)
print(rf_gridsearch)
plot(rf_gridsearch)
 


####GAM not used

#Week and state and year

gam_mod<-gam(y ~ s(new[,1])+ s(new[,5])+ s(new[,6])+ s(new[,7]) + s(new[,8])+s(new[,4]), data=new)

summary(gam_mod)
vis.gam(gam_mod)

futureVal <-predict(gam_mod, n.ahead = 2)
#https://m-clark.github.io/generalized-additive-models/application.html#multiple-predictors
#pruning random forest 


ob_v_pred_test_plot = ggplot(combo, aes(x = Preds, y = Original)) +
  geom_point() +
  geom_abline()


ob_v_pred_test_plot #way over estimating 



# https://gist.github.com/gunthergl/bc1202b93b672e384c77da9b3769b91d was not able to implement this graphics

##GAM Viz

futureVal <-predict(gam_mod, n.ahead = 2) 

pred_week <- df$Week

preddata = data.frame(Week = seq(.4, 1, length = 100),
                      Edu = mean(mod_gam2$model$Edu),
                      Health = mean(mod_gam2$model$Health))

futureVal <-predict(fit, n.ahead = 168)

fits = predict(mod_gam2, newdata=testdata, type='response', se=T)
predicts = data.frame(testdata, fits) %>% 
  mutate(lower = fit - 1.96*se.fit,
         upper = fit + 1.96*se.fit)

plot_mod_gam2_response = ggplot(aes(x=Income,y=fit), data=predicts) +
  geom_ribbon(aes(ymin = lower, ymax=upper), fill='gray90') +
  geom_line(color='#00aaff') +
  theme_trueMinimal()




