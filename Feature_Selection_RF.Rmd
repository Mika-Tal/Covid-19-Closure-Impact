---
title: "Feature_Select_RF"
author: "ClareCallahan"
date: "4/17/2021"
output: html_document
---

```{r setup, include=FALSE}
loadlibs = function(libs) {
  for(lib in libs) {
    class(lib)
    if(!do.call(require,as.list(lib))) {install.packages(lib)}
    do.call(require,as.list(lib))
  }
}
libs = c("tidyverse","data.table","stargazer", "knitr", "shiny",
         "tidymodels", "lubridate", "rpart.plot", "caret", "e1071",
         "readxl", "fuzzyjoin", "mgcv", "randomForest", "glmnet")
loadlibs(libs)
```

```{r}
setwd("~/GitHub/Covid-19-Closure-Impact")

#df<-read.csv('Covid_Pred.csv')

df<- read.csv('shiny_merged_dataset_example.csv')
  names(df) <-tolower(names(df))
  
colnames(df)[which(names(df) == "covid_measure")] <- "y"
  
  drops<-c( "x") #droping 
df <-df[, -which(names(df) %in% drops)]
  
 df<- df%>%
  mutate_at(c('date'), ~ as.Date(., "%Y-%m-%d")) %>% 
  mutate(two_week_forecast_date = date + 14)%>% 
  mutate_if(is.character, as.factor)

  
  # Get latest date 
latest_date = max(df$date)
#Two week outcome 
twoWeek_df = df %>% 
  select(date, state, y) %>% 
  rename(two_week_outcome = y,
         two_week_forecast_date = date) 
#Merge with original to create a working df
working_df = df %>% 
  left_join(twoWeek_df,
            by = c("state" = "state",
                   "two_week_forecast_date" = "two_week_forecast_date")) %>% 
  mutate(year = as.factor(year(two_week_forecast_date)),
         week = as.factor(week(two_week_forecast_date)))



working_df[is.na(working_df)] <-0

#y = covid_measure
colnames(working_df)[which(names(working_df) == "y")] <- "two_week_backcast"
colnames(working_df)[which(names(working_df) == "two_week_outcome")] <- "y"

#names(df)[names(df) == "Outcome.Variable"] <- "original_y" #creating consitency 
#names(df)[names(df) == "Other"] <- "Other_Race"  #"Other is not meaningful in output

```



```{r}
##Train/Test split 
#n<-lm_feats%>% count() 
#n<-as.numeric(n/2)
#data2 = lm_feats[sample(1:nrow(lm_feats)),]  # permute rows


#Create train set
train_df = function(df) {
  #Call addForecastCols function to create the outcome variable
  #create variable for latest date for which two week covid measure is avaiable
  latest_date = max(df$date)
  #Create a training set - reserving the last two weeks with obvserved 
  #two_week__outcome are reserved as a test set. 
  train = df[df$two_week_forecast_date <= (latest_date - 14), ]
  return(train)
}

  latest_date = max(glm_feats$date)
  #Create a training set - reserving the last two weeks with obvserved 
  #two_week__outcome are reserved as a test set. 
  train = glm_feats[glm_feats$two_week_forecast_date <= (latest_date - 14), ]

#Create test set
test_df = function(df) {
  #create variable for latest date for which two week covid measure is avaiable
  latest_date = max(df$date)
  #Create a test set - using the last two weeks for which two_week_outcom is observed. 
  test = df[(df$two_week_forecast_date <= latest_date) &
                      (df$two_week_forecast_date > (latest_date - 14)), ]
  return(test)
}


#Create prediction set - for all states
pred_df = function(df) {
  #Call addForecastCols function to create the outcome variable
  #create variable for latest date for which two week covid measure is avaiable
  latest_date = max(df$date)
  #Create a prediction set - using the  two weeks for which two_week_outcom is not observed. 
  pred = df[df$two_week_forecast_date > latest_date +7, ]
  return(pred)
}




```


```{r}
#glm_feats$date<-working_df$date   
#glm_feats<- glm_feats%>% mutate_at(c('date'), ~ as.Date(., "%Y-%m-%d"))
#glm_feats$glm_feats$two_week_forecast_date <- working_df$

#forecast_col<-addForecastCols(glm_feats)
datatrain<-train_df(working_df)
datatest<-test_df(working_df)
datapreds<- pred_df(working_df)

drops<-c("year","week","two_week_forecast_date")

#datatest$two_week_forecast_date
datatrain <-datatrain[, -which(names(datatrain) %in% drops)]
datatest <- datatest[, -which(names(datatest) %in% drops)]
datapreds <- datapreds[, -which(names(datapreds) %in% drops)]
#datacleaning for randomforest 
```


```{r}

#let Tobi know what gets kept 
drops<-c( "year", "week", "two_week_forecast_date") #droping 
working_df <-working_df[, -which(names(working_df) %in% drops)]
##Moving Ouctome Variable to front of dataset for ease of splitting
col_idx <- grep("^y$", names(working_df))
working_df<- working_df[, c(col_idx, (1:ncol(working_df))[-col_idx])]



```
##Split
```{r}

end<-ncol(working_df)
x <- working_df[,2:end]
y <- working_df[,1]

#Removing Y from the tuning paratmers 

```

## Tuning
The following is tuning the number of varaibles reandomple sampled as candiate at each split (mtry)
```{r}

# Algorithm Tune (tuneRF)
set.seed(10)
bestmtry <- tuneRF(x, y, stepFactor=1.5, improve=1e-5, ntree=500)
print(bestmtry)
bestmtry_var<- bestmtry[1,1]

```


```{r}

r.forest <- function(working_df){
  rf <- randomForest(y ~ ., mtry= bestmtry_var, 
  data=working_df)

  varImpPlot(rf,sort=TRUE, n.var=min(10, nrow(rf$importance)),
           type=NULL, class=NULL, scale=TRUE, 
           main=deparse(substitute(rf))) 
  
  features <- as.data.frame(rf$importance)
  features <-as.data.frame(setNames(cbind(rownames(features), features, row.names= NULL), c("Feature", "NodPurity"))) 
  top<- top_n(features, 10, features$NodPurity)
  top_f<-as.vector(top$Feature)

  return(top_f)
}
 



rf.tops <-function(sample_df, top_f){
  new<-sample_df%>%
  select(all_of(c(top_f)))
  
  new$y<-sample_df$y

  return(new)

}

#glment select levels of sparcity....  

```

```{r}

tops <-r.forest(working_df)

datatrain<-rf.tops(datatrain, tops)
datatest<-rf.tops(datatest,tops)
datapreds<- rf.tops(datapreds,tops)

```


###Geocoding 


#Data from: https://public.opendatasoft.com/explore/dataset/us-zip-code-latitude-and-longitude/export/ 
Process needed to create 2D for 'state' to be incorporated into GLM with poly option 


#Geotagging for glmnet
```{r}

#setwd("~/GitHub/Covid-19-Closure-Impact/Data")
geo_join<- function(df){
geo<- read.csv('us-zip-code-latitude-and-longitude.csv', header= FALSE, stringsAsFactors = FALSE)

geo<- as.data.frame(geo)

geo<-geo%>% separate(V1, into=c("Zip", "City", "State", "Latitude","Longitude","Timezone","Daylight_savings", "geopoint"), sep=";" )

geo<- geo[-1,]

geo$Latitude<-as.numeric(geo$Latitude)
geo$Longitude<-as.numeric(geo$Longitude)

names(geo) <-tolower(names(geo))
  
state_latLong <- geo%>%
  group_by(state)%>%
  summarise(latitude = mean(latitude, na.rm = TRUE),
            longitude = mean(longitude, na.rm = TRUE))
  return(left_join(df, state_latLong, by='state'))
}
```


#Joining Long/Lat data and selected features
```{r}
# this step should be moved to data cleaning, ask if their data is by state or county, county can be a direct match to the original dataset 
datatrain_lm<- geo_join(datatrain)
datatest_lm<- geo_join(datatest)
datapreds_lm<-geo_join(datapreds)
#id<-rownames(features)
#features<-cbind(id=id, features)

```


#cleaning on test/train/ preds 
```{r}

cleaning_lm<- function(df){
df1<-df[, -which(names(df) %in% c("state"))]#%>% 
  #select(-1) #removing 'id'

col_idx <- grep("^y$", names(df1))
df1 <- df1[, c(col_idx, (1:ncol(df1))[-col_idx])]

#dropping date, cannot create a poly w/ cbind() after polys created
date_hold<- as.data.frame(df1$date)
colnames(date_hold)<-"date"
#two_week_forecast_date<-as.data.frame(features1$two_week_forecast_date)
drops<-c( "date") #droping 
df1<-df1[, -which(names(df1) %in% drops)]

 feats<- function(xf, column_numbers) {

   xf %>% 
    mutate_at(vars(column_numbers), funs(sqr = (.)^2))%>%
   mutate_at(vars(column_numbers), funs(cube =(.)^3))
   }
end<-ncol(features1)

#, two_week_forecast_date
return(cbind(feats(df1, 2:end), date_hold)) #do not include y or "id" in poly calcs
}
#one<- as.character(top[1,1])

#typeof(features1$two_week_prior)

```

```{r}
datatrain_lm<- cleaning_lm(datatrain_lm)
datatest_lm<- cleaning_lm(datatest_lm)
datapreds_lm<-cleaning_lm(datapreds_lm)

```
## CV.lm (with poly )
```{r}
#install.packages('DAAG')
library(DAAG)

#datatrain[is.na(datatrain)] <-0

#x_test<- model.matrix(~., -1 datatrain[, 1])

train_cvlm<- CVlm(data=datatrain_lm, form.lm = formula(y~.))

predict(train_cvlm, newx = datatest_lm %>% select(-y, -id)%>% as.matrix(), newy= datatest_lm$y)

```

##Linear features only

features2<-features[, -which(names(features) %in% c("state"))]

n<-features2%>% count() 
n<-as.numeric(n/2)
data3 = features2[sample(1:nrow(features2)),]  # permute rows

datatrain2 = data3[(1:n),]
datatest2 = data3[-(1:n),]


##Glmnet 
```{r}


train_glm<- cv.glmnet(
  x = datatrain_lm %>% select(-y) %>% as.matrix(),
  y = datatrain_lm$y %>% as.matrix(), relax = FALSE, standardize = FALSE, normalize=FALSE, winsfrac=0)

i <- which(train_glm$lambda == train_glm$lambda.min)
mse.min <- train_glm$cvm[i]


glm_test <-predict(train_glm, newx = datatest_lm %>% select(-y)%>% as.matrix(), newy= datatest_lm$y)

glm_preds <-predict(train_glm, newx = datapreds_lm %>% select(-y)%>% as.matrix(), newy= datapreds_lm$y)

#combo<- as.data.frame(cbind(glm_preds, datatest2$y))
#combo<-combo%>%
#  rename(Preds='1', 
 #        Original = V2)

```

```{r}

plot(glm_preds)
plot(glm_preds,xvar="lambda",label=TRUE)

```


```{r}

plot(combo)

combo$Error_abs <-100*abs(combo$Original - combo$Preds)/combo$Original

combo$MSE<-(combo$Original - combo$Preds)^2 

mean(combo$MSE)
mean(combo$Error_abs)

ggplot(combo, aes(x=Error_abs)) + geom_boxplot()
ggplot(combo, aes(x=MSE)) + geom_boxplot()

```


#df1 = df %>%
# mutate_if(is.character, as.factor) #%>% 
#mutate_if(is.factor, forcats::fct_lump_min, min=100) 
#df1$new_cases<- as.factor(df1$new_cases)

t<- as.numeric(count(df)*.75)

set.seed(12345) 
df2 = df[sample(1:nrow(df)),]
train = df2[1:t,]
test = df2[-(1:t),]


control <- trainControl(method="repeatedcv", number=10, repeats=3, search="grid")
set.seed(seed)
tunegrid <- expand.grid(.mtry=c(1:15))
rf_gridsearch <- train(Class~., data=dataset, method="rf", metric=metric, tuneGrid=tunegrid, trControl=control)
print(rf_gridsearch)
plot(rf_gridsearch)
 

####GAM not used

#Week and state and year

gam_mod<-gam(y ~ s(new[,1])+ s(new[,5])+ s(new[,6])+ s(new[,7]) + s(new[,8])+s(new[,4]), data=new)

summary(gam_mod)
vis.gam(gam_mod)

futureVal <-predict(gam_mod, n.ahead = 2)
#https://m-clark.github.io/generalized-additive-models/application.html#multiple-predictors
#pruning random forest 


ob_v_pred_test_plot = ggplot(combo, aes(x = Preds, y = Original)) +
  geom_point() +
  geom_abline()


ob_v_pred_test_plot #way over estimating 



# https://gist.github.com/gunthergl/bc1202b93b672e384c77da9b3769b91d was not able to implement this graphics

##GAM Viz

futureVal <-predict(gam_mod, n.ahead = 2) 

pred_week <- df$Week

preddata = data.frame(Week = seq(.4, 1, length = 100),
                      Edu = mean(mod_gam2$model$Edu),
                      Health = mean(mod_gam2$model$Health))

futureVal <-predict(fit, n.ahead = 168)

fits = predict(mod_gam2, newdata=testdata, type='response', se=T)
predicts = data.frame(testdata, fits) %>% 
  mutate(lower = fit - 1.96*se.fit,
         upper = fit + 1.96*se.fit)

plot_mod_gam2_response = ggplot(aes(x=Income,y=fit), data=predicts) +
  geom_ribbon(aes(ymin = lower, ymax=upper), fill='gray90') +
  geom_line(color='#00aaff') +
  theme_trueMinimal()




