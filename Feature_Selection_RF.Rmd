---
title: "Feature_Select_RF"
author: "ClareCallahan"
date: "4/17/2021"
output: html_document
---

```{r setup, include=FALSE}
loadlibs = function(libs) {
  for(lib in libs) {
    class(lib)
    if(!do.call(require,as.list(lib))) {install.packages(lib)}
    do.call(require,as.list(lib))
  }
}
libs = c("tidyverse","data.table","stargazer", "knitr", "shiny",
         "tidymodels", "lubridate", "rpart.plot", "caret", "e1071",
         "readxl", "fuzzyjoin", "mgcv", "randomForest", "glmnet")
loadlibs(libs)
```

```{r}
#setwd("~/GitHub/Covid-19-Closure-Impact")

#df<-read.csv('Covid_Pred.csv')

df<- read.csv('shiny_merged_dataset_example.csv')
  names(df) <-tolower(names(df))
  
colnames(df)[which(names(df) == "covid_measure")] <- "y"
  
  drops<-c( "x") #droping 
df <-df[, -which(names(df) %in% drops)]
  
 df<- df%>%
  mutate_at(c('date'), ~ as.Date(., "%Y-%m-%d")) %>% 
  mutate(two_week_forecast_date = date + 14)%>% 
  mutate_if(is.character, as.factor)

  
  # Get latest date 
latest_date = max(df$date)
#Two week outcome 
twoWeek_df = df %>% 
  select(date, state, y) %>% 
  rename(two_week_outcome = y,
         two_week_forecast_date = date) 
#Merge with original to create a working df
working_df = df %>% 
  left_join(twoWeek_df,
            by = c("state" = "state",
                   "two_week_forecast_date" = "two_week_forecast_date")) %>% 
  mutate(year = as.factor(year(two_week_forecast_date)),
         week = as.factor(week(two_week_forecast_date)))



working_df[is.na(working_df)] <-0

#y = covid_measure
colnames(working_df)[which(names(working_df) == "y")] <- "two_week_backcast"
colnames(working_df)[which(names(working_df) == "two_week_outcome")] <- "y"

#names(df)[names(df) == "Outcome.Variable"] <- "original_y" #creating consitency 
#names(df)[names(df) == "Other"] <- "Other_Race"  #"Other is not meaningful in output

```



```{r}
##Train/Test split 
#n<-lm_feats%>% count() 
#n<-as.numeric(n/2)
#data2 = lm_feats[sample(1:nrow(lm_feats)),]  # permute rows


#Create train set
train_df = function(df) {
  #Call addForecastCols function to create the outcome variable
  #create variable for latest date for which two week covid measure is avaiable
  latest_date = max(df$date)
  #Create a training set - reserving the last two weeks with obvserved 
  #two_week__outcome are reserved as a test set. 
  train = df[df$two_week_forecast_date <= (latest_date - 14), ]
  return(train)
}

<<<<<<< HEAD
  latest_date = max(working_df$date)
  #Create a training set - reserving the last two weeks with obvserved 
  #two_week__outcome are reserved as a test set. 
  train = working_df[working_df$two_week_forecast_date <= (latest_date - 14), ]
=======
  latest_date = max(df$date)
  #Create a training set - reserving the last two weeks with obvserved 
  #two_week__outcome are reserved as a test set. 
  train = df[df$two_week_forecast_date <= (latest_date - 14), ]
>>>>>>> 029a6e4f06346400a4b34657ec2444de3744d7a2

#Create test set
test_df = function(df) {
  #create variable for latest date for which two week covid measure is avaiable
  latest_date = max(df$date)
  #Create a test set - using the last two weeks for which two_week_outcom is observed. 
  test = df[(df$two_week_forecast_date <= latest_date) &
                      (df$two_week_forecast_date > (latest_date - 14)), ]
  return(test)
}


#Create prediction set - for all states
pred_df = function(df) {
  #Call addForecastCols function to create the outcome variable
  #create variable for latest date for which two week covid measure is avaiable
  latest_date = max(df$date)
  #Create a prediction set - using the  two weeks for which two_week_outcom is not observed. 
  pred = df[df$two_week_forecast_date > latest_date +7, ]
  return(pred)
}




```


```{r}
#glm_feats$date<-working_df$date   
#glm_feats<- glm_feats%>% mutate_at(c('date'), ~ as.Date(., "%Y-%m-%d"))
#glm_feats$glm_feats$two_week_forecast_date <- working_df$

#forecast_col<-addForecastCols(glm_feats)
datatrain<-train_df(working_df)
datatest<-test_df(working_df)
datapreds<- pred_df(working_df)

#drops<-c("year","week","two_week_forecast_date")

#datatest$two_week_forecast_date
#datatrain <-datatrain[, -which(names(datatrain) %in% drops)]
#datatest <- datatest[, -which(names(datatest) %in% drops)]
#datapreds <- datapreds[, -which(names(datapreds) %in% drops)]
#datacleaning for randomforest 
```


```{r}

drops<-c( "year", "week", "two_week_forecast_date") #droping 
working_df <-working_df[, -which(names(working_df) %in% drops)]
##Moving Ouctome Variable to front of dataset for ease of splitting
col_idx <- grep("^y$", names(working_df))
working_df<- working_df[, c(col_idx, (1:ncol(working_df))[-col_idx])]



```
##Split
```{r}

end<-ncol(working_df)
x <- working_df[,2:end]
y <- working_df[,1]

#Removing Y from the tuning paratmers 

```

## Tuning
The following is tuning the number of varaibles reandomple sampled as candiate at each split (mtry)
```{r}

# Algorithm Tune (tuneRF)
set.seed(10)
bestmtry <- as.data.frame (tuneRF(x, y, stepFactor=1.5, improve=1e-5, ntree=500))
print(bestmtry)


bestmtry_var<- bestmtry[which(bestmtry$OOBError == min(bestmtry$OOBError)),1]



```


```{r}

r.forest <- function(working_df){
 
  rf <- randomForest(y ~ ., mtry= bestmtry_var, 
  data=working_df)

  varImpPlot(rf,sort=TRUE, n.var=min(10, nrow(rf$importance)),
           type=NULL, class=NULL, scale=TRUE, 
           main=deparse(substitute(rf))) 
  
  features <- as.data.frame(rf$importance)
  features <-as.data.frame(setNames(cbind(rownames(features), features, row.names= NULL), c("Feature", "NodPurity"))) 
  top<- top_n(features, 10, features$NodPurity)
  top_f<-as.vector(top$Feature)

  return(top_f)
}
 

rf.tops <-function(sample_df, top_f){
  new<-sample_df%>%
  select(all_of(c(top_f)))
  
  new$y<-sample_df$y

  return(new)

}

#glment select levels of sparcity....  

```

```{r}

tops <-r.forest(working_df)


  varImpPlot(rf,sort=TRUE, n.var=min(10, nrow(rf$importance)),
           type=NULL, class=NULL, scale=TRUE, 
           main=deparse(substitute(rf))) 
  
```

###Start of GLMNET
```{r}
datatrain_rf<-rf.tops(datatrain, tops)
datatest_rf<-rf.tops(datatest,tops)
datapreds_rf<- rf.tops(datapreds,tops)

```


###Geocoding 


#Data from: https://public.opendatasoft.com/explore/dataset/us-zip-code-latitude-and-longitude/export/ 
Process needed to create 2D for 'state' to be incorporated into GLM with poly option 


#Geotagging for glmnet
```{r}

#setwd("~/GitHub/Covid-19-Closure-Impact/Data")
geo_join<- function(df){
geo<- read.csv('us-zip-code-latitude-and-longitude.csv', header= FALSE, stringsAsFactors = FALSE)

geo<- as.data.frame(geo)

geo<-geo%>% separate(V1, into=c("Zip", "City", "State", "Latitude","Longitude","Timezone","Daylight_savings", "geopoint"), sep=";" )

geo<- geo[-1,]

geo$Latitude<-as.numeric(geo$Latitude)
geo$Longitude<-as.numeric(geo$Longitude)

names(geo) <-tolower(names(geo))
  
state_latLong <- geo%>%
  group_by(state)%>%
  summarise(latitude = mean(latitude, na.rm = TRUE),
            longitude = mean(longitude, na.rm = TRUE))
  return(left_join(df, state_latLong, by='state'))
}
```


#Joining Long/Lat data and selected features
```{r}
# this step should be moved to data cleaning, ask if their data is by state or county, county can be a direct match to the original dataset 
datatrain_lm<- geo_join(datatrain_rf)
datatest_lm<- geo_join(datatest_rf)
datapreds_lm<-geo_join(datapreds_rf)
#id<-rownames(features)
#features<-cbind(id=id, features)

```


#cleaning on test/train/ preds 
```{r}

cleaning_lm<- function(df){
df1<-df[, -which(names(df) %in% c("state"))]#%>% 
  #select(-1) #removing 'id'

col_idx <- grep("^y$", names(df1))
df1 <- df1[, c(col_idx, (1:ncol(df1))[-col_idx])]

#dropping date, cannot create a poly w/ cbind() after polys created
date_hold<- as.data.frame(df1$date)
colnames(date_hold)<-"date"
#two_week_forecast_date<-as.data.frame(features1$two_week_forecast_date)
drops<-c("date") #droping 
df1<-df1[, -which(names(df1) %in% drops)]

   feats<- function(xf, column_numbers) {

<<<<<<< HEAD
   xf %>% 
    mutate_at(vars(column_numbers), funs(sqr = (.)^2))%>%
   mutate_at(vars(column_numbers), funs(cube =(.)^3))
   }
=======
    xf %>% 
     mutate_at(vars(column_numbers), funs(sqr = (.)^2))%>%
     mutate_at(vars(column_numbers), funs(cube =(.)^3))
     }
 
>>>>>>> 029a6e4f06346400a4b34657ec2444de3744d7a2
end<-ncol(df1)

#, two_week_forecast_date
return(cbind(feats(df1, 2:end), date_hold)) #do not include y or "id" in poly calcs
} 
#one<- as.character(top[1,1])

#typeof(features1$two_week_prior)

```

```{r}
datatrain_poly<- cleaning_lm(datatrain_lm)
datatest_poly<- cleaning_lm(datatest_lm)
datapreds_poly<-cleaning_lm(datapreds_lm)

```


##Glmnet 
```{r}

datatrain_glmnet<- datatrain_poly %>%
mutate(across(where(is.factor), ~ fct_lump_lowfreq(.))) %>%
model.matrix(object= ~ .-1, . , contrasts.arg =
                                                 lapply(data.frame(.[,sapply(data.frame(.), is.factor)]),
                                                        contrasts, contrasts = FALSE))

datatest_glmnet<- datatest_poly %>%
mutate(across(where(is.factor), ~ fct_lump_lowfreq(.))) %>%
model.matrix(object= ~ .-1, . , contrasts.arg =
                                                                lapply(data.frame(.[,sapply(data.frame(.), is.factor)]),
                                                        contrasts, contrasts = FALSE))

datapreds_glmnet<- datapreds_poly%>%
mutate(across(where(is.factor), ~ fct_lump_lowfreq(.))) %>%
model.matrix(object= ~ .-1, . , contrasts.arg =
                                                                lapply(data.frame(.[,sapply(data.frame(.), is.factor)]),
                                                        contrasts, contrasts = FALSE))



train_glm<- glmnet(
  x = datatrain_glmnet[,-1],
  y = datatrain_glmnet[,1], relax = FALSE, nfolds= 3)

#plot(train_glm)

lamMin<- min(train_glm[["lambda"]])

test_glm<-predict(train_glm, newx= datatest_glmnet[,-1], newy=datatest_glmnet[,1], s = lamMin , interval="confidence")

preds_glm<- predict(train_glm, newx= datapreds_glmnet[,-1], newy=datapreds_glmnet[,1], s = lamMin , interval="confidence")
```
#RMSE testing 
```{r}

test<- as.data.frame(test) 
glm_test<- as.data.frame(datatest_glmnet)

preds_act<- cbind(test, glm_test$y)
RMSE_glm<- sqrt(mean(preds_act[,2]-preds_act[,1])^2)
preds_act$Observed<- preds_act[,1]
preds_act$Predicted<- preds_act[,2]
preds_act$two_week_forecast_date <- datapreds$two_week_forecast_date

final_preds<- cbind(preds, datapreds_geo)
final_preds$Predicted<- final_preds[,1]

```


###Plotting 


```{r}

  final_preds = final_preds%>%
    mutate(state = tolower(setNames(state.name, state.abb)[state]))
  #create map data 

 #create map data 
  map = map_data("state") %>% 
    full_join(final_preds, by = c("region" = "state"))
  #plot
  map_plot = ggplot(map, aes(long, lat, group = group)) +
    geom_polygon(aes(fill = Predicted), color = "white")+
    scale_fill_viridis_c(option = "B", direction=-1)+
    ggtitle("Predicted COVID Measure (per 100,000) Next Week")

map_plot

```


```{r}
obs_vs_pred_plot = ggplot(preds_act, aes(x = Observed, y = Predicted)) +
  geom_point() +
  geom_abline()

obs_vs_pred_plot


 obs_vs_pred = preds_act %>% 
    mutate(Observed = log(Observed),
           Predicted = log(Predicted))
  
  obs_vs_pred_plot = ggplot(obs_vs_pred, aes(x = Observed, y = Predicted),
                            color = 'white') +
    geom_point() +
    geom_abline() +
    #geom_line(aes(y = log(baselineRMSE(test)), color = "#F8766D")) +
    xlab("Log(Observed)") +
    ylab("Log(Predicted)") +
    ggtitle("Log GLM Prediction v. Observed")
    #scale_colour_manual(name = FALSE, values =c('#00BFC4'='#00BFC4','#F8766D'='#F8766D'),
                        #labels = c('45-degree','Baseline')) +
    theme_bw()

  
  obs_vs_pred_plot


```


#Predictions all plot
```{r}


  #Plot Predictions
  outcome_all = datatrain %>% 
    select(two_week_forecast_date, y) %>%
    rename(Date = two_week_forecast_date,
           Outcome = y) %>% 
    mutate (Pred_vs_Obs = "Observed") %>% 
    rbind(tibble(Date = preds_act$two_week_forecast_date,
                 Outcome = preds_act$Predicted,
                 Pred_vs_Obs = "Predicted"))
 

 outcome_plot_all = ggplot(outcome_all, aes(x = Date, y = Outcome))+
    geom_point(aes(color = Pred_vs_Obs)) +
    theme_bw()+
   ggtitle("Glmnet Predictions")
  
   outcome_plot_all
```

#Residual Density plot
```{r}

    GLMResids = datatest_poly %>% 
      select(two_week_backcast, y) %>% 
      rename(Observed = y) %>% 
      mutate(Model = "GLM") %>% 
      bind_cols(tibble(Predicted = preds_act$Predicted)) %>% 
      mutate(Residuals = Predicted - Observed) %>% 
      select(Residuals, Model)
    #df for baseline residuals

    BLResids = tibble(Residuals = mean(datatest_poly$two_week_backcast) - datatest_poly$y,
                      Model = "Baseline")
    #Combine dfs for the plot
    resids = GLMResids %>% 
      bind_rows(BLResids)
    #Plot
    resids_plot = ggplot(resids, aes(x = Residuals, fill = Model)) +
      geom_density( color = 'white', alpha = 0.7) +
      theme_bw()
 resids_plot

```